{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Práctica de Web Scraping\n",
    "\n",
    "Se va a considerar una de las páginas vista en la teoría que contiene fotos de trenes:https://www.vialibre-ffe.com/multi_foto.asp?cs=mult. En esta página aparece un menú con varios grupos de fotos de trenes. A su vez, cada grupo contiene un conjunto de subgrupos de fotos. Por ejemplo, el grupo __Renfe operadora__ se encuentra en la página https://www.vialibre-ffe.com/multi_ind_fotos.asp?cat=mu01."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image(filename='Captura1.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dentro de este grupo por ejemplo se encuentra el subgrupo __Serie120 en Irún-Hendaya__ en la página https://www.vialibre-ffe.com/multi_galeria.asp?gal=524. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image(filename='Captura2.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En dicho subgrupo se encuentran las imágenes de dicho subgrupo. Por ejemplo, a continuación, se muestra una de las imágenes del subgrupo __Serie120 en Irún-Hendaya__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image(filename='Captura1.png')\n",
    "#for i in range(1,4):\n",
    "#    Image(filename='Captura'+str(i)+'.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las imágenes contenidas en dicha página se pueden encontrar en las etiquetas __&lt;li> &lt;img ...__ que son hijas de la etiqueta __&lt;ul class=\"pgwSlideshow\">__. Por ejemplo en la página de ejemplo, la primera imagen de dicha página es:\n",
    "\n",
    "   __&lt;li>&lt;img src=\"multimedia/galerias/IRUN120/2Alvia_120.jpg\" alt=\"\" data-description=\"\">&lt;/li>__\n",
    "   \n",
    "A continuación, se puede ver el contenido html de esa página."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "url=\"https://www.vialibre-ffe.com/multi_galeria.asp?gal=524\"\n",
    "r = requests.get(url)\n",
    "html = r.text\n",
    "print(html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se pide:\n",
    "\n",
    " 1. Crear un programa en __Python__ que muestre un menú con los grupos de fotos, y que pregunte al usuario que grupo de fotos quiere visitar. Se puede asociar a cada grupo un número, y solicitar al usuario que introduzca por teclado el número del grupo. A continuación, se mostrará los subgrupos de ese grupo, y se le preguntará nuevamente al usuario que subgrupo de fotos quiere procesar. Igual que antes, se puede asociar a cada subgrupo un número, y que introduzca por teclado el número del subgrupo. Como resultado se creará un directorio en el disco local para el subgrupo elegido y en el directorio se bajarán las imágenes de los trenes. Se imprimirá por pantalla las urls de las imágenes que se están bajando. Toda la información utilizada en el programa, debe ser extraida de las páginas consideradas usando BeautifulSoup[6 puntos]\n",
    " \n",
    " 2. Crear un minibuscador en __Python__ que pregunte al usuario un conjunto de palabras clave, y  recorra el sitio web buscando todos los subgrupos en cuyo título aparezca alguna de las palabras claves. Como resultado debe mostrar los subgrupos encontrados, listando el nombre y la url de cada subgrupo [4 puntos]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Normas de entrega\n",
    "\n",
    "* Fecha tope de entrega: 18/11/2017\n",
    "* La entrega se realizará subiendo al campus virtual un notebook de Jupyter con la solución. El archivo tendrá como nombre WebScraping_GrupoX donde X será el número de grupo correspondiente.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------Menú Principal:------------------------------------\n",
      "1. Renfe Operadora\n",
      "2. Ferrocarriles autonómicos\n",
      "3. Metropolitanos\n",
      "4. Tranvías\n",
      "5. Otros operadores\n",
      "6. Infraestructuras\n",
      "7. Instalaciones\n",
      "8. Estaciones\n",
      "9. Internacional\n",
      "10. Históricas\n",
      "11. Museos y trenes\n",
      "12. Varios\n",
      "Elige una opcion: 5\n",
      "------------------------------------Menú para Otros operadores:------------------------------------\n",
      "1. Transporte de madera España-Portugal 2014\n",
      "2. Tren de alta velocidad Avril de Talgo\n",
      "3. 25 años de trenes \"Pendolino\"\n",
      "4. Trenes Civity de CAF para servicios regionales en Trieste\n",
      "5. Feve - Trenes\n",
      "6. El tren frutero de Eurocargo\n",
      "7. Teco Logitren Valencia-Zaragoza\n",
      "8. Orient Express\n",
      "9. Feve\n",
      "Elige una opcion: 5\n",
      "------------------------------------URLs de las imágenes:------------------------------------\n",
      "https://www.vialibre-ffe.com/multimedia/galerias/Feve_Trenes/FEVE_tren001.jpg\n",
      "https://www.vialibre-ffe.com/multimedia/galerias/Feve_Trenes/FEVE_tren002.jpg\n",
      "https://www.vialibre-ffe.com/multimedia/galerias/Feve_Trenes/FEVE_tren003.jpg\n",
      "https://www.vialibre-ffe.com/multimedia/galerias/Feve_Trenes/FEVE_tren004.jpg\n",
      "https://www.vialibre-ffe.com/multimedia/galerias/Feve_Trenes/FEVE_tren005.jpg\n",
      "https://www.vialibre-ffe.com/multimedia/galerias/Feve_Trenes/FEVE_tren006.jpg\n",
      "https://www.vialibre-ffe.com/multimedia/galerias/Feve_Trenes/FEVE_tren007.jpg\n",
      "https://www.vialibre-ffe.com/multimedia/galerias/Feve_Trenes/FEVE_tren008.jpg\n",
      "https://www.vialibre-ffe.com/multimedia/galerias/Feve_Trenes/FEVE_tren009.jpg\n",
      "https://www.vialibre-ffe.com/multimedia/galerias/Feve_Trenes/FEVE_tren010.jpg\n",
      "https://www.vialibre-ffe.com/multimedia/galerias/Feve_Trenes/FEVE_tren011.jpg\n",
      "https://www.vialibre-ffe.com/multimedia/galerias/Feve_Trenes/FEVE_tren012.jpg\n",
      "https://www.vialibre-ffe.com/multimedia/galerias/Feve_Trenes/FEVE_tren013.jpg\n",
      "https://www.vialibre-ffe.com/multimedia/galerias/Feve_Trenes/FEVE_tren014.jpg\n",
      "https://www.vialibre-ffe.com/multimedia/galerias/Feve_Trenes/FEVE_tren015.jpg\n",
      "https://www.vialibre-ffe.com/multimedia/galerias/Feve_Trenes/FEVE_tren016.jpg\n",
      "https://www.vialibre-ffe.com/multimedia/galerias/Feve_Trenes/FEVE_tren017.jpg\n",
      "https://www.vialibre-ffe.com/multimedia/galerias/Feve_Trenes/FEVE_tren018.jpg\n",
      "https://www.vialibre-ffe.com/multimedia/galerias/Feve_Trenes/FEVE_tren019.jpg\n",
      "------------------------------------Imágenes descargadas------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import urllib\n",
    "import urllib.request\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def explorarFerrocarriles():\n",
    "    #URL base de la pagina web\n",
    "    url=\"https://www.vialibre-ffe.com\"\n",
    "    #HTML de la pagina en la que empezamos a trabajar\n",
    "    html=urllib.request.urlopen(\"https://www.vialibre-ffe.com/multi_foto.asp?cs=mult\")\n",
    "    soup=BeautifulSoup(html.read(),'html.parser')\n",
    "    primero=soup.find_all(\"a\") # Buscamos todos los links\n",
    "    # Regex para reconocer las URLs que nos interesan\n",
    "    patron=re.compile(r\"\\/multi\\_ind\\_fotos\\.asp\\?cat=mu.*\")\n",
    "    # Lista que contendra los nombres de los links\n",
    "    listaNombres=[]\n",
    "    # Lista que contendra las URLs\n",
    "    listaURL=[]\n",
    "    # Parsea el HTML de la primera pagina para buscar las URLs que coinciden\n",
    "    # con el patron; despues los guarda en listas\n",
    "    for etiqueta in primero:\n",
    "        nomb = etiqueta.contents\n",
    "        link = etiqueta.get('href',None)\n",
    "        matches=patron.search(link)\n",
    "        # Si el patron coincide\n",
    "        if matches != None:\n",
    "            listaNombres.append(nomb[0])\n",
    "            listaURL.append(link)\n",
    "    # Muestra por pantalla las opciones disponibles\n",
    "    print(\"------------------------------------Menú Principal:------------------------------------\")\n",
    "    con = 0\n",
    "    for nomb in listaNombres:\n",
    "        con = con + 1\n",
    "        print(str(con) + \". \" + nomb)\n",
    "    # Pide al usuario la opcion por pantalla y comprueba que la opcion sea valida\n",
    "    opt = input(\"Elige una opcion: \")\n",
    "    while (int(opt)<1 or int(opt) >len(listaNombres)):\n",
    "           print(\"No existe esa opción. Elige otra\")\n",
    "           opt = input(\"Elige una opcion: \")\n",
    "    #Creamos una carpeta con el nombre de la opcion introducida y me meto en ella\n",
    "    #si ya existe esa carpeta no la creo solo me meto en ella\n",
    "    if os.path.exists(str(listaNombres[int(opt)-1])) is False:\n",
    "        os.makedirs(str(listaNombres[int(opt)-1]))\n",
    "    os.chdir(str(listaNombres[int(opt)-1]))\n",
    "    # Elige el link sobre el que trabajar de la lista anterior\n",
    "    link = url+listaURL[int(opt)-1]\n",
    "    # Se repite de nuevo el proceso para el nuevo link, que es\n",
    "    # un submenu de opciones.\n",
    "    html=urllib.request.urlopen(link)\n",
    "    soup=BeautifulSoup(html.read(),'html.parser')\n",
    "    segundo=soup.find_all(\"a\")\n",
    "    # El patron para el submenu es diferente; asi como las listas.\n",
    "    patron2=re.compile(r\"multi\\_galeria\\.asp\\?gal=.*\")\n",
    "    listaURL2 = []\n",
    "    listaNombres2 = []\n",
    "    # Añade a la lista los links que coinciden con el patron buscado y\n",
    "    # no esten ya en la lista (algunos links aparecian duplicados)\n",
    "    for etiqueta in segundo:\n",
    "        link = etiqueta.get('href',None)\n",
    "        matches=patron2.search(link)\n",
    "        if matches != None and link not in listaURL2:\n",
    "            listaURL2.append(link)\n",
    "            listaNombres2.append(etiqueta.contents[1].get('alt',None))\n",
    "    # Muestra las nuevas opciones por pantalla\n",
    "    print(\"------------------------------------Menú para \"+str(listaNombres[int(opt)-1])+\":------------------------------------\")\n",
    "    con = 0\n",
    "    for nomb in listaNombres2:\n",
    "        con = con + 1\n",
    "        print(str(con) + \". \" + nomb)\n",
    "    # Pide la eleccion del usuario por pantalla y comprueba que la opcion es valida\n",
    "    opt = input(\"Elige una opcion: \")\n",
    "    while (int(opt)<1 or int(opt) >len(listaNombres2)):\n",
    "           print(\"No existe esa opción. Elige otra\")\n",
    "           opt = input(\"Elige una opcion: \")\n",
    "    #Creo otra carpeta para indicar la otra opcion, en esata será donde guarde las fotos\n",
    "    #Si ya existe esa carpeta solo me meto en ella, pero sin crearla\n",
    "    if os.path.exists(str(listaNombres2[int(opt)-1])) is False:\n",
    "        os.makedirs(str(listaNombres2[int(opt)-1]))\n",
    "    os.chdir(str(listaNombres2[int(opt)-1]))\n",
    "    \n",
    "    #Tengo el link donde estan las fotos que quiero descargar\n",
    "    link = url+'/'+listaURL2[int(opt)-1]\n",
    "    #Cogo el html de esa pagina, que es donde estan las imagenes que quiero\n",
    "    html=urllib.request.urlopen(link).read()\n",
    "    soup=BeautifulSoup(html, 'html.parser')\n",
    "    #Guardo en una lista las etiquetas ul de la pagina\n",
    "    ul=[]\n",
    "    ul=soup.find_all(\"ul\")\n",
    "    #Consigo la ul <ul class=\"pgwSlideshow\">,que es la ultima que aparece en el html\n",
    "    li =ul[len(ul)-1]\n",
    "    #Guardo en una lista las etiquetas li que aparecen (que cada una de ellas es una imagen)\n",
    "    lo=li.find_all(\"li\")\n",
    "    j=1 #contador para ir nombrando a las imagenes una vez las guardemos\n",
    "    print(\"------------------------------------URLs de las imágenes:------------------------------------\")\n",
    "    #Recorro cada imagen\n",
    "    for imagen in lo:\n",
    "        #Consigo en que posicion esta el link de la imagen\n",
    "        posInicio=str(imagen).find('multimedia')\n",
    "        posFinal=str(imagen).find('\"/>')\n",
    "        imagenUrl=\"\"\n",
    "        #Recorro eso para obtener la direccion de la foto\n",
    "        while (posInicio!=posFinal):\n",
    "            imagenUrl=imagenUrl+str(imagen)[posInicio]\n",
    "            posInicio=posInicio+1\n",
    "        #Url de cada imagen\n",
    "        urlEntera=url+'/'+imagenUrl\n",
    "        print(urlEntera)#url entera a mostrar \n",
    "        #Descargo la foto\n",
    "        try:\n",
    "            img = urllib.request.urlopen(urlEntera)\n",
    "            manf=open(\"imagen\"+str(j)+\".jpg\",\"wb\")\n",
    "            while True:\n",
    "                info=img.read(100000)\n",
    "                if len(info)<1:\n",
    "                    break\n",
    "                manf.write(info)\n",
    "            manf.close()\n",
    "            j=j+1\n",
    "        except:\n",
    "            error=0\n",
    "    print(\"------------------------------------Imágenes descargadas------------------------------------\")\n",
    "    #Vuelvo a la caprtea raiz donde estaba\n",
    "    os.chdir(\"../../\")\n",
    "    \n",
    "#Ejercicio 1\n",
    "explorarFerrocarriles()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
